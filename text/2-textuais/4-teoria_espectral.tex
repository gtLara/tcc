\chapter{Teoria Espectral Univariada}\label{chap:spectral_analysis}

\section*{Introdução}

O seguinte capítulo discute a representação espectral de séries temporais
univariadas. São exploradas transformações lineares e não lineares.

O desenvolvimento de uma representação espectral para uma realização
teoricamente infinita de um processo estocástico se inicia no reconhecimento da
impossibilidade de uma transformada de Fourier desse tipo de sinal, seguido de
uma apresentação do teorema de Wiener Khinchin. O resultado da representação
desenvolvida, conhecido como densidade de potência espectral, é interpretado.
Em seguida, restringindo a classe de sinais estacionários para realizações de
processos ARMA, conseguimos derivar expressões fechadas para a densidade
de potência espectral, resultado importante em teoria de
estimação~\cite{estimation_theory}.

Em seguida inicia-se uma discussão sobre representações não lineares por meio
de uma generalização natural da função de autocorrelação e subsequentemente a
classe de distribuições de Cohen. O problema geral dessa classe de
representações e a principal proposta para sua resolução nos leva às
transformadas conhecidas como \emph{Smoothed Pseudo Wigner Ville
Distributions} (SPWVD).

\section{Análise Estacionária}

Sinais estacionários no sentido amplo são, por definição
(seção~\ref{sec:stationarity}), sinais de potência. Como a transformada de
Fourier é bem definida apenas para sinais de energia finita sinais estocásticos
estacionários não possuem uma transformada de Fourier no sentido tradicional.
Para desenvolver uma representação espectral desse tipo de sinal é necessário
definir o conceito de densidade de potência espectral e concluir que essa
função é proporcional ao quadrado da magnitude de uma transformada de Fourier
hipotética.

\subsubsection{Densidade de Potência Espectral}

Constatamos inicialmente o teorema de Parseval, em que $F\{\}$ representa a
transformada de Fourier

$$ E = \int^{\infty}_{-\infty} |x(t)|^2 dt = \frac{1}{2\pi} \int^{\infty}_{-\infty} |F\{x(t)\}(\omega)|^2 d\omega $$

Estendendo essa definição para potência de sinal temos

$$ P = \lim_{T \to \infty} \frac{1}{2T}\frac{1}{2\pi} \int^{T}_{-T}|F\{x(t)\}(\omega)|^2 d\omega$$

Note que apesar de $F\{x(t)\}$ não ser bem definida a relação acima ainda é
válida se $|F\{x(t)\}|^2$ for descrita de uma forma diferente, o que será
feito em breve.

A potência de um sinal pode ser reescrita representando a transformada de
Fourier de $x(t)$ por $X(\omega)$ como

$$ P = \lim_{T \to \infty} \frac{1}{2T}\frac{1}{2\pi} \int^{T}_{-T}|X(\omega)|^2 d\omega $$

Onde $\lim_{T \to \infty}\frac{1}{2\pi} \frac{1}{2T} |X(\omega)|² $
é reconhecida como uma função de densidade. A função densidade de potência
espectral é finalmente definida como

$$ S_{x}(\omega) = \lim_{T \to \infty}\frac{1}{2\pi} \frac{1}{2T} |X(\omega)|² $$

O nome dessa função é bem informativo para sua interpretação: $S_{x}(\omega)$
representa a contribuição das componentes de frequência de $x(t)$ localizadas
em $\omega + d\omega$ para a potência do sinal como um todo. A definição de
$|X(\omega)|^2$ necessária para que essa função faça sentido é fornecida pelo
teorema de Wiener-Khinchin.

\subsection{Teorema de Wiener-Khinchin}

O teorema de Wiener Khinchin pode ser desenvolvido da seguinte maneira

$$ |X(\omega)^2| = X(\omega)X^*(\omega) = F(F^{-1}(X(\omega))*(F^{-1}(X^*(\omega))) = F(x(t) * x^*(-t)) = F(x(t) * x(-t))$$

Examinando a parte mais à direita dessa igualdade observamos que a função que
está sendo transformada corresponde à convolução de $x(t)$ com uma versão
espelhada de si mesmo. Isso é precisamente a definição de autocorrelação.
Assumindo ergodicidade podemos agora expressar a magnitude ao quadrado da
transformada de Fourier de $x(t)$ como a transformada de Fourier de sua
função de autocorrelação.

$$|X(\omega)_T|^2 = \frac{1}{2\pi}\int_{-T}^{T} \rho(t)e^{-j \omega t}dt$$

Esse resultado é conhecido como o teorema de Wiener-Khinchin e permite uma
representação espectral bem definida para sinais estocásticos estacionários.

Note que a transformada de Fourier da autocorrelação de um sinal real é
em si puramente real, propriedade consistente com nossa noção de magnitude ao
quadrado.

\subsection{Espectro de um Processo ARMA}

Tomando a magnitude ao quadrado da transformada Z da forma de recorrência
geral de um processo ARMA (~\ref{ssec:arma_l}) obtemos a seguinte função de
transferência

$$ H(z) = \frac{1 + \sum_{i}^{q} b_k z^{-k}}{1 + \sum_{i}^{q} a_k z^{-k}} $$

que é excitada por ruído branco de forma a gerar uma realização de um processo
ARMA. Podemos agora expressar a densidade de potência espectral de um processo
ARMA como

$$ S_{ARMA}(\omega) = |H(z)|^2 S_{\varepsilon} $$

\begin{equation}\label{eq:arma_spectrum}
     S_{ARMA}(\omega) = \frac{\sigma^2 |1 + \sum_{k=1}^{q} b_k e^{-j\omega k}|^2}{2\pi|1 + \sum_{k=1}^{p} a_k e^{-j\omega k}|^2}
\end{equation}

Essa definição é usada como uma forma de estimação paramétrica de espectro:
os parâmetros são inferidos no domínio do tempo e usados pela relação acima
para sugerir um espectro.

Visualizaremos agora o espectro de alguns processos ARMA.

\subsubsection{MA(1)}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{figures/ma_1_spectrum.png}
    \caption{Espectro de um processo MA(1) com
    $\protect \beta_1 = -0.5$}
    \label{fig:ma_1_spectrum}
\end{figure}

\subsubsection{AR(1)}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{figures/ar_1_spectrum_1.png}
    \caption{Espectro de um processo AR(1) com
    $\protect \alpha_1 = 0.8$}
    \label{fig:ar_1_spectrum_1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{figures/ar_1_spectrum_2.png}
    \caption{Espectro de um processo AR(1) com
    $\protect \alpha_1 = -0.8$}
    \label{fig:ar_1_spectrum_2}
\end{figure}

\subsubsection{AR(2)}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{figures/ar_2_spectrum.png}
    \caption{Espectro de um processo AR(2) com
    $\protect \alpha_1 = 0.5$ and $\protect \alpha_2 = -0.25$}
    \label{fig:ar_2_spectrum}
\end{figure}

\subsubsection{ARMA(4, 3)}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{figures/arma_4_3_spectrum.png}
    \caption{Espectro de um processo ARMA(4, 3)}
    \label{fig:ar_4_3_spectrum}
\end{figure}


\subsection{Efeitos de raízes unitárias em espectros ARMA}

A introdução de raízes unitárias no polinômio de média móvel ou autoregressivo
de um processo ARMA tem claros efeitos em seu conteúdo espectral, como
mencionado na subseção~\ref{ssec:ma_roots}. O impacto dessas operações no
espectro de um processo pode ser compreendido pelas alterações resultantes ao
gráfico de polos e zeros ou pela modificação da série temporal.

Uma análise do gráfico de polos e zeros de um sistema ARMA torna evidente o
efeito de integração na função de transferência do sistema: um polo é
introduzido em $e^{j\omega}=0$ de forma a fornecer energia às componentes de
baixa frequência do sinal. Reciprocamente podemos compreender diferenciação,
que é a introdução de um zero em $e^{j\omega}=0$, como a supressão de
componentes de baixa frequência, resultado em uma operação análoga à filtragem
passa-altas.

No domínio do tempo o efeito de diferenciação pode ser observado comparando as
figuras~\ref{fig:ARMA2-1} e~\ref{fig:ARMA2-1-diff}. A série diferenciada
claramente tem mais energia distribuída em torno de componentes de alta
frequência. Isso é de fato verdadeiro para qualquer sinal: diferenciação
no domínio do tempo age de forma a enviesar o conteúdo espectral para altas
frequências. O recíproco também é verdadeiro: integral um sinal tende seu
conteúdo espectral para baixas frequências por meio da introdução de tendências
estocásticas.

Apresenta-se agora uma versão diferenciada do espectro do processo MA(1) da
figura~\ref{fig:ma_1_spectrum}. Note que o sinal passa por uma filtragem
passa altas, como mencionado.

\subsubsection{MA(1) Diferenciado}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{figures/diff_ma_1_spectrum.png}
    \caption{Espectro de um processo MA(1) com $\protect \beta_1 = -0.5$
    diferenciado.}
    \label{fig:diff_ma_1_spectrum}
\end{figure}

\section{Representações Não Estacionárias}

O fato da grande maioria dos sinais produzidos por fontes reais serem não
estacionários leva à necessidade de desenvolver algum tipo de representação
espectral não estacionária. A densidade de potência espectral, definida pela
transformada de Wiener-Khinchin, é incapaz de representar variações espectrais
ao longo do tempo. Uma ideia natural para gerar uma ``densidade de potência
espectral variante no tempo'' é tomar a transformada de Fourier de uma função
de autocorrelação variante no tempo. Tal função é chamada de função de
autocorrelação instantânea. A representação resultante é não linear, gerando
termos cruzados prejudiciais para o objetivo da transformada.

\subsection{Função de Autocorrelação Instantânea}\label{ssec:inst_autocorr}

A função de autocorrelação instantânea é, na realidade, só a função de
autocorrelação de um sinal não estacionário escrita em uma forma específica.
Interessantemente o termo função de autocorrelação passou a denominar uma
função dependente apenas de um atraso $\tau$, como é o caso da autocorrelação
para sinais estacionários, ao invés de uma função dependente de dois
instantes no tempo $t_1$ e $t_2$. Inicialmente reescrevemos a função de
autocorrelação geral $R_{xx}$ de um sinal $x(t)$ como

$$ R_{xx}(t_1, t_2) = E[x(t_1)x(t_2)] $$

Que também pode ser escrita em função de um instante de tempo $t$ e um atraso
$\tau$ como

$$ R_{x}(t, \tau) = E[x(t)x(t-\tau)] $$

Que é ligeiramente mais conveniente para computações. Note que se $x(t)$ é
estacionário a dependência no tempo é removida porque $R_{xx}$ possui o
mesmo valor para todo $t$.

Um pequeno ajuste de notação nos leva a

$$ \mathcal{R}_{x}(t, \tau) = E\left[x\left(t - \frac{\tau}{2}\right)x\left(t + \frac{\tau}{2}\right)\right] $$

Usando um novo símbolo para indicar que enfim chegamos à função de
autocorrelação instantânea $\mathcal{R}_{x}$.

Uma representação em tempo frequência agora é natural. Já que o
teorema de Wiener-Khinchin afirma que o espectro de um sinal estacionário é
a transformada de Fourier de sua função de autocorrelação podemos de forma
análoga assumir que a representação espectral de um sinal não estacionário
será dado pela transformada de Fourier ao longo do eixo $\tau$ da função de
autocorrelação instantânea. Isso nos leva à distribuição de Wigner Ville.

\subsection{Distribuição de Wigner-Ville}

Definimos a distribuição de Wigner-Ville (WVD) como

$$ \mathcal{W}_{x}(t, f) =  \int_{-\infty}^{\infty} \mathcal{R}_{x}(t, \tau) e^{-j\omega \tau}d\tau$$

$$ \mathcal{W}_{x}(t, f) =  \int_{-\infty}^{\infty} x\left(t - \frac{\tau}{2}\right)x\left(t + \frac{\tau}{2}\right) e^{-j\omega \tau}d\tau$$

Essa representação natural pode ser considerada uma densidade de potência
espectral instantânea. Sabe-se que a WVD otimiza a resolução tempo frequência
~\cite{tfr_comparison}, uma propriedade desejável de representações tempo
frequência (TFRs). Veremos agora que isso não ocorre sem problemas.

\subsubsection{Termos cruzados}

Por construção a WVD é uma representação quadrática. Pelo princípio de
superposição quadrática~\cite{quadratic_freq_representation} sabemos que se
$x(t) = \mu x_1(t) + \lambda x_2(t)$ a representação $WVD$ de $x(t)$ é dada
por

$$ \mathcal{W}_{x} = \mu^2\mathcal{W}_{x_1} + \lambda^2\mathcal{W}_{x_2} + 2(\lambda\mu)^2(\mathcal{W}_{x_1 , x_2}) $$

Onde $\mathcal{W}_{z, y}$ representa a WVD cruzada entre $x$ e $y$. Já que todo
sinal de complexidade relevante é uma combinação linear na base de $cos(t)$ e
$sin(t)$ esperamos que uma quantidade considerável de componentes cruzados seja
introduzida. Esse é conhecido como o problema de termos cruzados das
representações de Wigner Ville e é um dos motivos da transformada não ser a
melhor escolha para grande parte de sinais reais apesar de sua ótima resolução
tempo-frequência.

É conhecido que os termos cruzados possuem padrões de alta frequência
~\cite{martin_lol}, levando à possibilidade de tornar a WVD mais representativa
de seus auto termos por meio de filtragem. As diferentes formas possíveis e
úteis de filtrar a WVD leva a um subconjunto da classe de distribuição de
Cohen.

\subsection{\emph{Smoothed Pseudo Wigner Ville Distributions}}

A maioria dos membros da classe de distribuições de Cohen são essencialmente
versões filtradas da WVD~\cite{tfr_comparison}. Um caso particularmente útil
é conhecido como a \emph{Smoothed Pseudo Wigner Ville Distribution}
(Smoothed Pseudo Wigner Ville Distribution).

$$ SPWVD(t, f) = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty} h_t (t - \tau) h_f(f - \phi)d\tau d\phi $$

em que $h_t$ representa o filtro aplicado ao longo do tempo e $h_f$ ao longo
da frequência.

Se o projeto dos filtros for bem sucedido a supressão de termos cruzados é
suficientemente bem sucedida a ponto de justificar o uso da SPWVD ao invés de
métodos mais simples de representação em tempo frequência.
